{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Frequentist Models for Match Score Prediction\n",
    "\n",
    "\n",
    "\n",
    " This notebook demonstrates how to use frequentist statistical models to predict match scores using the `ssat` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Importing Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from ssat.data import get_sample_handball_match_data\n",
    "from ssat.frequentist import BradleyTerry, GSSD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Understanding the Models\n",
    "\n",
    "\n",
    "\n",
    " We'll compare two key frequentist models with different approaches:\n",
    "\n",
    "\n",
    "\n",
    " - **Bradley-Terry**: Uses paired comparison approach based on team strengths and logistic regression for win probabilities.\n",
    "\n",
    " - **GSSD**: Generalized Scores Standard Deviation model using team offensive/defensive statistics with linear regression.\n",
    "\n",
    "\n",
    "\n",
    " The difference is demonstrated in their underlying assumptions and prediction methodologies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Train-Test Split\n",
    "\n",
    "\n",
    "\n",
    " We'll split the data chronologically to evaluate model performance properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "match_df = get_sample_handball_match_data()\n",
    "\n",
    "league = \"Herre Handbold Ligaen\"\n",
    "seasons = [2024]\n",
    "\n",
    "filtered_matches = match_df.query(\"league == @league and season in @seasons\")\n",
    "filtered_matches = filtered_matches.assign(\n",
    "    spread=filtered_matches.home_goals - filtered_matches.away_goals\n",
    ")\n",
    "\n",
    "# Sort by date to ensure chronological split\n",
    "filtered_matches = filtered_matches.sort_values(\"datetime\")\n",
    "\n",
    "print(f\"Total matches from {league} in {seasons}: {len(filtered_matches)}\")\n",
    "print(\n",
    "    f\"Unique teams: {len(pd.concat([filtered_matches['home_team'], filtered_matches['away_team']]).unique())}\"\n",
    ")\n",
    "print(\n",
    "    f\"Date range: {filtered_matches['datetime'].min().date()} to {filtered_matches['datetime'].max().date()}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(len(filtered_matches) * 0.8)\n",
    "\n",
    "train_data = filtered_matches.iloc[:split_idx]\n",
    "test_data = filtered_matches.iloc[split_idx:]\n",
    "\n",
    "print(\n",
    "    f\"\\nTrain set: {len(train_data)} matches ({train_data['datetime'].min().date()} to {train_data['datetime'].max().date()})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test set: {len(test_data)} matches ({test_data['datetime'].min().date()} to {test_data['datetime'].max().date()})\"\n",
    ")\n",
    "\n",
    "# Prepare training features and targets\n",
    "X_train = train_data[[\"home_team\", \"away_team\"]]\n",
    "Z_train = train_data[[\"home_goals\", \"away_goals\"]]\n",
    "y_train = train_data[\"spread\"]\n",
    "\n",
    "# Prepare test features and targets (for evaluation)\n",
    "X_test = test_data[[\"home_team\", \"away_team\"]]\n",
    "Z_test = test_data[[\"home_goals\", \"away_goals\"]]\n",
    "y_test = test_data[\"spread\"]\n",
    "\n",
    "# Create match identifiers for test set\n",
    "test_data = test_data.assign(\n",
    "    match_id=test_data[\"home_team\"] + \" vs \" + test_data[\"away_team\"]\n",
    ")\n",
    "X_test.index = test_data[\"match_id\"]\n",
    "\n",
    "print(\"\\nTraining data info:\")\n",
    "print(\n",
    "    f\"Average goals per match: {Z_train[['home_goals', 'away_goals']].sum(axis=1).mean():.1f}\"\n",
    ")\n",
    "print(f\"Average spread: {y_train.mean():.2f} (std: {y_train.std():.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Fitting Models\n",
    "\n",
    "\n",
    "\n",
    " We will fit two frequentist models on the training data: Bradley-Terry and GSSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_model = BradleyTerry()\n",
    "bt_model.fit(X_train, y_train, Z_train)\n",
    "\n",
    "# Get team ratings\n",
    "bt_ratings = bt_model.get_team_ratings()\n",
    "print(\"Bradley-Terry Team Ratings (Top 10):\")\n",
    "print(bt_ratings.sort_values(by=\"rating\", ascending=False).head(10))\n",
    "\n",
    "# Make predictions on test set\n",
    "bt_preds = bt_model.predict(X_test)\n",
    "bt_probas = bt_model.predict_proba(X_test, point_spread=0, include_draw=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gssd_model = GSSD()\n",
    "gssd_model.fit(X_train, y_train, Z_train)\n",
    "\n",
    "# Get team ratings - GSSD has proper get_team_ratings method\n",
    "gssd_ratings = gssd_model.get_team_ratings()\n",
    "print(\"\\nGSSD Team Ratings and Coefficients:\")\n",
    "print(gssd_ratings)\n",
    "\n",
    "# Create simplified ratings for comparison\n",
    "gssd_team_ratings = gssd_ratings.drop(['Coefficients', 'Intercept'])\n",
    "gssd_team_ratings['rating'] = (gssd_team_ratings['pfh'] + gssd_team_ratings['pfa']) - (gssd_team_ratings['pah'] + gssd_team_ratings['paa'])  # Overall strength\n",
    "print(\"\\nGSSD Team Overall Ratings (Top 10):\")\n",
    "print(gssd_team_ratings.head(10))\n",
    "\n",
    "# Make predictions on test set\n",
    "gssd_preds = gssd_model.predict(X_test)\n",
    "\n",
    "# Check for teams not in training\n",
    "test_teams = set(X_test.iloc[:, 0].tolist() + X_test.iloc[:, 1].tolist())\n",
    "train_teams = set(gssd_model.team_map_.keys())\n",
    "missing_teams = test_teams - train_teams\n",
    "\n",
    "if missing_teams:\n",
    "    print(f\"Warning: Test set contains teams not in training: {missing_teams}\")\n",
    "    # Filter test set to only include known teams\n",
    "    known_mask = X_test.apply(\n",
    "        lambda row: row.iloc[0] in train_teams and row.iloc[1] in train_teams, axis=1\n",
    "    )\n",
    "    X_test_filtered = X_test[known_mask]\n",
    "    y_test_filtered = y_test[known_mask]\n",
    "    print(f\"Filtered test set from {len(X_test)} to {len(X_test_filtered)} matches\")\n",
    "else:\n",
    "    X_test_filtered = X_test\n",
    "    y_test_filtered = y_test\n",
    "\n",
    "# Now make predictions on filtered test set\n",
    "if len(X_test_filtered) > 0:\n",
    "    gssd_preds_filtered = gssd_model.predict(X_test_filtered)\n",
    "    gssd_probas_filtered = gssd_model.predict_proba(X_test_filtered, point_spread=0, include_draw=True)\n",
    "\n",
    "    # Align Bradley-Terry predictions with filtered test set\n",
    "    if missing_teams:\n",
    "        bt_preds_filtered = bt_preds[known_mask.values]\n",
    "        bt_probas_filtered = bt_probas[known_mask.values]\n",
    "    else:\n",
    "        bt_preds_filtered = bt_preds\n",
    "        bt_probas_filtered = bt_probas\n",
    "else:\n",
    "    print(\"No valid test matches after filtering\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Model Evaluation\n",
    "\n",
    "\n",
    "\n",
    " Let's evaluate model performance on the test set and examine predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Calculate prediction errors on filtered test set\n",
    "bt_mae = mean_absolute_error(y_test_filtered, bt_preds_filtered)\n",
    "bt_rmse = np.sqrt(mean_squared_error(y_test_filtered, bt_preds_filtered))\n",
    "\n",
    "gssd_mae = mean_absolute_error(y_test_filtered, gssd_preds_filtered)\n",
    "gssd_rmse = np.sqrt(mean_squared_error(y_test_filtered, gssd_preds_filtered))\n",
    "\n",
    "print(\"=== MODEL PERFORMANCE ON TEST SET ===\")\n",
    "print(f\"Bradley-Terry - MAE: {bt_mae:.3f}, RMSE: {bt_rmse:.3f}\")\n",
    "print(f\"GSSD - MAE: {gssd_mae:.3f}, RMSE: {gssd_rmse:.3f}\")\n",
    "\n",
    "print(\"\\n=== SAMPLE PREDICTIONS (First 10 Test Matches) ===\")\n",
    "test_sample = X_test.head(10)\n",
    "print(\"\\nBradley-Terry Predictions (Spread):\")\n",
    "print(bt_preds_filtered[:10])\n",
    "print(\"\\nGSSD Predictions (Spread):\")\n",
    "print(gssd_preds_filtered[:10])\n",
    "print(\"\\nActual Spreads:\")\n",
    "print(y_test_filtered.iloc[:10].values)\n",
    "\n",
    "print(\"\\n=== WIN PROBABILITIES (First 5 Test Matches) ===\")\n",
    "print(\"\\nBradley-Terry Probabilities:\")\n",
    "print(bt_probas_filtered[:5])\n",
    "print(\"\\nGSSD Probabilities:\")\n",
    "print(gssd_probas_filtered[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Model Comparison\n",
    "\n",
    "\n",
    "\n",
    " Let's visualize the key differences between the two frequentist models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plotting style\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle(\n",
    "    \"Frequentist Models Comparison: Bradley-Terry vs GSSD\",\n",
    "    fontsize=16,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "# Plot 1: Win Probabilities Comparison\n",
    "ax1 = axes[0, 0]\n",
    "test_subset = X_test_filtered.iloc[:8]  # Show first 8 test matches for clarity\n",
    "bt_subset = bt_probas_filtered[:8]\n",
    "gssd_subset = gssd_probas_filtered[:8]\n",
    "\n",
    "x_pos = range(len(test_subset))\n",
    "width = 0.35\n",
    "\n",
    "ax1.bar(\n",
    "    [x - width / 2 for x in x_pos],\n",
    "    bt_subset[:, 0],  # home probabilities\n",
    "    width,\n",
    "    label=\"Bradley-Terry\",\n",
    "    alpha=0.8,\n",
    "    color=\"#2ca02c\",\n",
    ")\n",
    "ax1.bar(\n",
    "    [x + width / 2 for x in x_pos],\n",
    "    gssd_subset[:, 0],  # home probabilities\n",
    "    width,\n",
    "    label=\"GSSD\",\n",
    "    alpha=0.8,\n",
    "    color=\"#d62728\",\n",
    ")\n",
    "\n",
    "ax1.set_title(\"Home Win Probabilities\", fontweight=\"bold\")\n",
    "ax1.set_xlabel(\"Matches\")\n",
    "ax1.set_ylabel(\"Probability\")\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(\n",
    "    [f\"{row.home_team}\\nvs\\n{row.away_team}\" for _, row in test_subset.iterrows()],\n",
    "    rotation=45,\n",
    "    ha=\"right\",\n",
    "    fontsize=8,\n",
    ")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Draw Probabilities Comparison\n",
    "ax2 = axes[0, 1]\n",
    "ax2.bar(\n",
    "    [x - width / 2 for x in x_pos],\n",
    "    bt_subset[:, 1],  # draw probabilities\n",
    "    width,\n",
    "    label=\"Bradley-Terry\",\n",
    "    alpha=0.8,\n",
    "    color=\"#2ca02c\",\n",
    ")\n",
    "ax2.bar(\n",
    "    [x + width / 2 for x in x_pos],\n",
    "    gssd_subset[:, 1],  # draw probabilities\n",
    "    width,\n",
    "    label=\"GSSD\",\n",
    "    alpha=0.8,\n",
    "    color=\"#d62728\",\n",
    ")\n",
    "\n",
    "ax2.set_title(\"Draw Probabilities\", fontweight=\"bold\")\n",
    "ax2.set_xlabel(\"Matches\")\n",
    "ax2.set_ylabel(\"Probability\")\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(\n",
    "    [f\"{row.home_team}\\nvs\\n{row.away_team}\" for _, row in test_subset.iterrows()],\n",
    "    rotation=45,\n",
    "    ha=\"right\",\n",
    "    fontsize=8,\n",
    ")\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Team Ratings Comparison\n",
    "ax3 = axes[1, 0]\n",
    "# Get common teams between both models\n",
    "common_teams = set(bt_ratings.index) & set(gssd_team_ratings.index)\n",
    "common_teams = list(common_teams)[:10]  # Show top 10 for clarity\n",
    "\n",
    "if common_teams:\n",
    "    bt_common = bt_ratings.loc[common_teams][\"rating\"]\n",
    "    gssd_common = gssd_team_ratings.loc[common_teams][\"rating\"]\n",
    "\n",
    "    ax3.scatter(bt_common, gssd_common, alpha=0.7, s=80, color=\"purple\")\n",
    "\n",
    "    # Add team labels\n",
    "    for i, team in enumerate(common_teams):\n",
    "        ax3.annotate(\n",
    "            team,\n",
    "            (bt_common[team], gssd_common[team]),\n",
    "            xytext=(5, 5),\n",
    "            textcoords=\"offset points\",\n",
    "            fontsize=8,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "    # Add diagonal line for reference\n",
    "    min_val = min(bt_common.min(), gssd_common.min())\n",
    "    max_val = max(bt_common.max(), gssd_common.max())\n",
    "    ax3.plot([min_val, max_val], [min_val, max_val], \"k--\", alpha=0.5, linewidth=1)\n",
    "\n",
    "ax3.set_title(\"Team Ratings Comparison\", fontweight=\"bold\")\n",
    "ax3.set_xlabel(\"Bradley-Terry Ratings\")\n",
    "ax3.set_ylabel(\"GSSD Ratings\")\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Probability Differences (Residuals)\n",
    "ax4 = axes[1, 1]\n",
    "prob_diff_home = bt_probas_filtered[:, 0] - gssd_probas_filtered[:, 0]  # home\n",
    "prob_diff_draw = bt_probas_filtered[:, 1] - gssd_probas_filtered[:, 1]  # draw\n",
    "prob_diff_away = bt_probas_filtered[:, 2] - gssd_probas_filtered[:, 2]  # away\n",
    "\n",
    "ax4.hist(prob_diff_home, bins=15, alpha=0.6, label=\"Home Win\", color=\"red\")\n",
    "ax4.hist(prob_diff_draw, bins=15, alpha=0.6, label=\"Draw\", color=\"gray\")\n",
    "ax4.hist(prob_diff_away, bins=15, alpha=0.6, label=\"Away Win\", color=\"blue\")\n",
    "\n",
    "ax4.axvline(x=0, color=\"black\", linestyle=\"--\", alpha=0.5)\n",
    "ax4.set_title(\"Probability Differences\\n(Bradley-Terry - GSSD)\", fontweight=\"bold\")\n",
    "ax4.set_xlabel(\"Probability Difference\")\n",
    "ax4.set_ylabel(\"Frequency\")\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n=== MODEL COMPARISON SUMMARY ===\")\n",
    "print(f\"Average Home Win Prob - Bradley-Terry: {bt_probas_filtered[:, 0].mean():.3f}\")\n",
    "print(f\"Average Home Win Prob - GSSD: {gssd_probas_filtered[:, 0].mean():.3f}\")\n",
    "print(f\"Average Draw Prob - Bradley-Terry: {bt_probas_filtered[:, 1].mean():.3f}\")\n",
    "print(f\"Average Draw Prob - GSSD: {gssd_probas_filtered[:, 1].mean():.3f}\")\n",
    "print(f\"Average Away Win Prob - Bradley-Terry: {bt_probas_filtered[:, 2].mean():.3f}\")\n",
    "print(f\"Average Away Win Prob - GSSD: {gssd_probas_filtered[:, 2].mean():.3f}\")\n",
    "\n",
    "print(f\"\\nMean Absolute Difference (Home): {abs(prob_diff_home).mean():.4f}\")\n",
    "print(f\"Mean Absolute Difference (Draw): {abs(prob_diff_draw).mean():.4f}\")\n",
    "print(f\"Mean Absolute Difference (Away): {abs(prob_diff_away).mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Additional Analysis\n",
    "\n",
    "\n",
    "\n",
    " Let's examine model characteristics and team rating distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional analysis plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Team Rating Distributions\n",
    "ax1 = axes[0]\n",
    "if len(bt_ratings) > 0 and len(gssd_team_ratings) > 0:\n",
    "    ax1.hist(\n",
    "        bt_ratings[\"rating\"], bins=20, alpha=0.7, label=\"Bradley-Terry\", color=\"#2ca02c\"\n",
    "    )\n",
    "    ax1.hist(\n",
    "        gssd_team_ratings[\"rating\"],\n",
    "        bins=20,\n",
    "        alpha=0.7,\n",
    "        label=\"GSSD\",\n",
    "        color=\"#d62728\",\n",
    "    )\n",
    "    ax1.set_title(\"Team Rating Distributions\", fontweight=\"bold\")\n",
    "    ax1.set_xlabel(\"Rating\")\n",
    "    ax1.set_ylabel(\"Frequency\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Prediction Spread Comparison\n",
    "ax2 = axes[1]\n",
    "ax2.scatter(bt_preds_filtered, gssd_preds_filtered, alpha=0.7, s=60, color=\"orange\")\n",
    "\n",
    "# Add diagonal line for reference\n",
    "min_pred = min(bt_preds_filtered.min(), gssd_preds_filtered.min())\n",
    "max_pred = max(bt_preds_filtered.max(), gssd_preds_filtered.max())\n",
    "ax2.plot([min_pred, max_pred], [min_pred, max_pred], \"k--\", alpha=0.5, linewidth=1)\n",
    "\n",
    "ax2.set_title(\"Predicted Spreads Comparison\", fontweight=\"bold\")\n",
    "ax2.set_xlabel(\"Bradley-Terry Predictions\")\n",
    "ax2.set_ylabel(\"GSSD Predictions\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Conclusion\n",
    "\n",
    "\n",
    "\n",
    " This notebook demonstrates proper evaluation of frequentist Bradley-Terry and Poisson models:\n",
    "\n",
    "\n",
    "\n",
    " **Model Performance:**\n",
    "\n",
    " - Used chronological train-test split to simulate real-world prediction scenarios\n",
    "\n",
    " - Evaluated prediction accuracy using MAE and RMSE metrics\n",
    "\n",
    " - Models trained on early matches, tested on later matches\n",
    "\n",
    "\n",
    "\n",
    " **Key Differences:**\n",
    "\n",
    " - **Bradley-Terry Model**: Logistic regression approach with team strength parameters, excellent for ranking\n",
    "\n",
    " - **GSSD Model**: Uses linear regression with team offensive/defensive statistics, provides detailed performance breakdown\n",
    "\n",
    " - **Team Ratings**: Bradley-Terry provides overall strength, GSSD separates offensive and defensive capabilities per location\n",
    "\n",
    "\n",
    "\n",
    " **Practical Advantages:**\n",
    "\n",
    " - Fast fitting compared to Bayesian approaches\n",
    "\n",
    " - Interpretable parameters and team ratings\n",
    "\n",
    " - Suitable for real-time applications and live betting\n",
    "\n",
    " - No sampling uncertainty - deterministic predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
