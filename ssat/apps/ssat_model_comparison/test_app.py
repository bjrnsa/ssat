#!/usr/bin/env python3
"""
Test script for the SSAT Model Comparison Dashboard

This script performs basic functionality tests to ensure the application
works correctly.
"""

import sys
import traceback
from pathlib import Path

# Add current directory to path
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

def test_imports():
    """Test that all required imports work."""
    print("üîç Testing imports...")
    
    try:
        import panel as pn
        print("‚úÖ Panel imported successfully")
        
        import panel_material_ui as pmui
        print("‚úÖ Panel Material UI imported successfully")
        
        import pandas as pd
        print("‚úÖ Pandas imported successfully")
        
        import numpy as np
        print("‚úÖ NumPy imported successfully")
        
        import matplotlib.pyplot as plt
        print("‚úÖ Matplotlib imported successfully")
        
        import seaborn as sns
        print("‚úÖ Seaborn imported successfully")
        
        return True
        
    except ImportError as e:
        print(f"‚ùå Import error: {e}")
        return False

def test_app_creation():
    """Test that the app can be created without errors."""
    print("\nüèóÔ∏è  Testing app creation...")
    
    try:
        from app import SSATModelComparisonApp, create_app
        print("‚úÖ App module imported successfully")
        
        # Test class instantiation
        app_instance = SSATModelComparisonApp()
        print("‚úÖ App class instantiated successfully")
        
        # Test app creation function
        app = create_app()
        print("‚úÖ App created successfully")
        
        return True, app_instance
        
    except Exception as e:
        print(f"‚ùå App creation error: {e}")
        traceback.print_exc()
        return False, None

def test_data_generation():
    """Test that sample data generation works."""
    print("\nüìä Testing data generation...")
    
    try:
        from app import SSATModelComparisonApp
        app = SSATModelComparisonApp()
        
        # Test sample data
        data = app.sample_data
        print(f"‚úÖ Sample data created: {len(data)} matches")
        print(f"‚úÖ Teams: {data['home_team'].nunique()} unique teams")
        print(f"‚úÖ Columns: {list(data.columns)}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Data generation error: {e}")
        return False

def test_model_simulation():
    """Test that model training simulation works."""
    print("\nüß† Testing model simulation...")
    
    try:
        from app import SSATModelComparisonApp
        app = SSATModelComparisonApp()
        
        # Set up some models
        app.model_select.value = ['Bradley-Terry', 'GSSD']
        app._update_model_results()
        
        print(f"‚úÖ Model results generated: {len(app.model_results)} models")
        for model, results in app.model_results.items():
            print(f"  {model}: accuracy={results['accuracy']:.3f}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Model simulation error: {e}")
        return False

def test_visualization():
    """Test that visualization generation works."""
    print("\nüìà Testing visualization...")
    
    try:
        from app import SSATModelComparisonApp
        app = SSATModelComparisonApp()
        
        # Set up models and generate results
        app.model_select.value = ['Bradley-Terry', 'GSSD']
        app._update_model_results()
        
        # Test performance plot
        perf_fig = app.create_performance_comparison_plot()
        print("‚úÖ Performance comparison plot created")
        
        # Test prediction plot
        pred_fig = app._create_prediction_comparison_plot()
        print("‚úÖ Prediction comparison plot created")
        
        # Test data summary
        summary = app._create_data_summary_table()
        print("‚úÖ Data summary table created")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Visualization error: {e}")
        return False

def test_config():
    """Test that configuration file works."""
    print("\n‚öôÔ∏è  Testing configuration...")
    
    try:
        from config import APP_CONFIG, MODEL_CONFIG, DATA_CONFIG
        print("‚úÖ Configuration imported successfully")
        print(f"‚úÖ App title: {APP_CONFIG['title']}")
        print(f"‚úÖ Frequentist models: {len(MODEL_CONFIG['frequentist_models'])}")
        print(f"‚úÖ Sample teams: {len(DATA_CONFIG['teams'])}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Configuration error: {e}")
        return False

def run_all_tests():
    """Run all tests and report results."""
    print("üß™ SSAT Model Comparison Dashboard Tests")
    print("=" * 50)
    
    tests = [
        ("Imports", test_imports),
        ("App Creation", test_app_creation),
        ("Data Generation", test_data_generation),
        ("Model Simulation", test_model_simulation),
        ("Visualization", test_visualization),
        ("Configuration", test_config)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            if test_name == "App Creation":
                success, _ = test_func()
            else:
                success = test_func()
            results.append((test_name, success))
        except Exception as e:
            print(f"‚ùå {test_name} test failed with exception: {e}")
            results.append((test_name, False))
    
    # Print summary
    print("\nüìã Test Summary")
    print("-" * 30)
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    for test_name, success in results:
        status = "‚úÖ PASS" if success else "‚ùå FAIL"
        print(f"{test_name:20} {status}")
    
    print(f"\nOverall: {passed}/{total} tests passed")
    
    if passed == total:
        print("\nüéâ All tests passed! The dashboard should work correctly.")
        print("\nüí° Next steps:")
        print("1. Run: python demo.py")
        print("2. Or: python app.py")
        print("3. Or: panel serve app.py --show")
    else:
        print(f"\n‚ö†Ô∏è  {total - passed} test(s) failed. Please check the errors above.")
        print("\nüîß Common fixes:")
        print("1. Install missing dependencies: pip install -r requirements.txt")
        print("2. Check Python version (3.8+ recommended)")
        print("3. Verify panel and panel-material-ui versions")

if __name__ == "__main__":
    run_all_tests()
